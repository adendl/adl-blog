---
title: Accelerating PoC Development with ChatGPT and Red Hat OpenShift
date: '2023-01-30'
tags: ['Chat GPT', 'Open Source', 'Digital Health', 'Kafka', 'Edge Computing']
draft: false
summary: 'How to derive the OLS Estimator with matrix notation and a tour of math typesetting using markdown with the help of KaTeX.'
---

## Background

As a solutions architect, I spend most of my days doodling boxes and lines. Sure, I know how to code, but I'm not one of those 10x engineers you hear about. However, with the recent buzz around AI/ML models like GPT-3, I thought to myself, "Hey, why not give it a shot?"

My goal was simple: build a functional proof of concept app in a matter of hours using technologies I'm familiar with architecturally, but have limited hands-on experience with. And so, with digital health as my target, I set out on a wild and wacky journey. Could I do it with just my mad skills and a lot of help from conversational AI? Let's find out!

The source-code to my application is available [here](https://github.com/adendl/DigitalHealth-Edge).

## The Application

I wanted to build a relatively simple application that I could expand on later. I landed on a basic, and ultimately pretty useless application that would take in healthcare data from a medical device, stream it through to a Kafka cluster, store it into a database - and then have a frontend application visualise that healthcare data in real time. The application would consist of the following components:

![Image](https://github.com/adendl/adl-blog/blob/master/public/static/architecture1.png?raw=true)
| Application | Component |
| --------------------------- | ---------------------------- |
| Patient Vitals Data Generator | Node.js |
| Patient Vitals API - Kafka Producer | Node.js + Express |
| Kafka Cluster | Red Hat OpenShift Streams for Apache Kafka |
| Kafka Consumer | Python |
| Database | MongoDB |
| Data Access API | Node.js + Express |
| Data Visualisation Frontend | React + Highcharts |

Here is where Red Hat OpenShift comes in. Using [OpenShift Local](https://developers.redhat.com/products/openshift-local/overview), a lightweight distribution of OpenShift made to run on development machines - I could quickly containerise and deploy the code that I had written.

For certain application components, such as my Apache Kafka cluster, and my MongoDB database - I was able to quickly select and deploy these from within OpenShift itself.

## Building the Application

### Test JSON Data

Firstly, I needed some mock healthcare data to feed into my application. I asked ChatGPT to

```
generate a JSON object which includes information
about a patient's key vitals in an ER scenario.
```

```json:patient_vitals_payload_example.json
{
    "patient_id": "123456",
    "timestamp": "2022-12-01T10:30:00Z",
    "heart_rate": 72,
    "blood_pressure": {
        "systolic": 120,
        "diastolic": 80
    },
    "ecg_reading": {
        "rr_interval": 800,
        "p_wave": 0.05,
        "qrs_complex": 0.1,
        "t_wave": 0.2
    },
    "oxygen_saturation": 96,
    "heart_rate_variability": {
        "mean_rr": 792,
        "sdnn": 24,
        "rmssd": 36
    },
    "blood_chemistry": {
        "ldl": 130,
        "hdl": 40,
        "triglycerides": 150,
        "total_cholesterol": 220
    }
}
```

Hmmm...probably not super accurate - but I don't know enough to say otherwise. It will do.

### Node.js - Data Generator Service

Next, in lieu of a medical device to generate this information, I wanted to create a basic node.js application that would create some small variations on this data, and then post it to a REST API endpoint on a regular basis - every 0.5 seconds.
Copy and pasting the above JSON object, I asked ChatGPT

```
Based on this JSON payload, create a node.js application that generates
slightly different randomised values for each of the attributes,
and then POSTs it to the /vitals endpoint at a regular frequency.
Use HOSTURL and TIMEOUTTIME as environment variables to set the
hosturl and the interval.
```

```js:data_generator.js
const request = require('request');

const hostUrl = process.env.HOSTURL
const timeoutTime = process.env.TIMEOUTTIME

    async function sendRequest(interval) {
        while (true)
        {
            const patientData = {
                "patient_id": "123456",
                "timestamp": new Date().toISOString(),
                "heart_rate": Math.floor(Math.random() * 10) + 70,
                /** Removed for brevity
                **/
            await sleep(interval)
            request.post({
                url: `${hostUrl}/vitals`,
                json: patientData
            }, (error, response, body) => {
                if (error) {
                    console.log(error);
                } else {
                    console.log(response.statusCode, body);
                }
            });
        }
    }

    function sleep(ms) {
        return new Promise((resolve) => {
          setTimeout(resolve, ms);
        });
      }

sendRequest(timeoutTime);
```

### Node.js Express - Vitals API

Next up, to create a Node.js express server which is listening in on the /vitals endpoint to receive the message, and act as a Kafka producer and send it to a local Kafka cluster.

```
Based on the previous JSON payload, create a node.js express application
which listens on the /vitals endpoint, and then send that message to
a Kafka cluster, the Kafka connection string is an environment variable
called HOSTURL.
```

```js:vitals_api.js
const express = require('express');
const { Kafka } = require('kafkajs');
const bodyParser = require('body-parser');

const hostUrl = process.env.HOSTURL;
const app = express();
app.use(bodyParser.json());

const kafka = new Kafka({
  clientId: 'my-app',
  brokers: [hostUrl],
});
const producer = kafka.producer();

app.post('/vitals', async (req, res) => {
  const vitals = req.body;
  try {
    await producer.connect();
    await producer.send({
        topic: 'vitals',
        messages: [{ value: JSON.stringify(vitals) }],
    });
    res.status(200).send({ message: vitals });
    console.log("message sent");
  } catch (err) {
    console.log(err);
    res.status(500).send({ message: err });
  }
});

app.listen(3000, () => {
  console.log('Microservice listening on port 3000!');
});
```

Now to stand up a Kafka cluster. To do this, I made use of OpenShift operators to stand up a Kafka cluster. Operators automate the creation, configuration, and management of instances of Kubernetes-native applications.

![Image](https://github.com/adendl/adl-blog/blob/master/public/static/images/chatgpt-poc-development/operator.png?raw=true)

After installing the operator, I deployed the Red Hat Kafka cluster to my namespace.
![Image](https://github.com/adendl/adl-blog/blob/master/public/static/images/chatgpt-poc-development/deployed-operator.png?raw=true)

If you intend to use the `$` sign instead of math, you can escape it (`\$`), or specify the HTML entity (`&dollar;`) [^2]

Inline or manually enumerated footnotes are also supported. Click on the links above to see them in action.

[^2]: \$10 and &dollar;20.

# Deriving the OLS Estimator

Using matrix notation, let $n$ denote the number of observations and $k$ denote the number of regressors.

The vector of outcome variables $\mathbf{Y}$ is a $n \times 1$ matrix,

```tex
\mathbf{Y} = \left[\begin{array}
  {c}
  y_1 \\
  . \\
  . \\
  . \\
  y_n
\end{array}\right]
```

$$
\mathbf{Y} = \left[\begin{array}
  {c}
  y_1 \\
  . \\
  . \\
  . \\
  y_n
\end{array}\right]
$$

The matrix of regressors $\mathbf{X}$ is a $n \times k$ matrix (or each row is a $k \times 1$ vector),

```latex
\mathbf{X} = \left[\begin{array}
  {ccccc}
  x_{11} & . & . & . & x_{1k} \\
  . & . & . & . & .  \\
  . & . & . & . & .  \\
  . & . & . & . & .  \\
  x_{n1} & . & . & . & x_{nn}
\end{array}\right] =
\left[\begin{array}
  {c}
  \mathbf{x}'_1 \\
  . \\
  . \\
  . \\
  \mathbf{x}'_n
\end{array}\right]
```

$$
\mathbf{X} = \left[\begin{array}
  {ccccc}
  x_{11} & . & . & . & x_{1k} \\
  . & . & . & . & .  \\
  . & . & . & . & .  \\
  . & . & . & . & .  \\
  x_{n1} & . & . & . & x_{nn}
\end{array}\right] =
\left[\begin{array}
  {c}
  \mathbf{x}'_1 \\
  . \\
  . \\
  . \\
  \mathbf{x}'_n
\end{array}\right]
$$

The vector of error terms $\mathbf{U}$ is also a $n \times 1$ matrix.

At times it might be easier to use vector notation. For consistency, I will use the bold small x to denote a vector and capital letters to denote a matrix. Single observations are denoted by the subscript.

## Least Squares

**Start**:  
$$y_i = \mathbf{x}'_i \beta + u_i$$

**Assumptions**:

1. Linearity (given above)
2. $E(\mathbf{U}|\mathbf{X}) = 0$ (conditional independence)
3. rank($\mathbf{X}$) = $k$ (no multi-collinearity i.e. full rank)
4. $Var(\mathbf{U}|\mathbf{X}) = \sigma^2 I_n$ (Homoskedascity)

**Aim**:  
Find $\beta$ that minimises the sum of squared errors:

$$
Q = \sum_{i=1}^{n}{u_i^2} = \sum_{i=1}^{n}{(y_i - \mathbf{x}'_i\beta)^2} = (Y-X\beta)'(Y-X\beta)
$$

**Solution**:  
Hints: $Q$ is a $1 \times 1$ scalar, by symmetry $\frac{\partial b'Ab}{\partial b} = 2Ab$.

Take matrix derivative w.r.t $\beta$:

```tex
\begin{aligned}
  \min Q           & = \min_{\beta} \mathbf{Y}'\mathbf{Y} - 2\beta'\mathbf{X}'\mathbf{Y} +
  \beta'\mathbf{X}'\mathbf{X}\beta \\
                   & = \min_{\beta} - 2\beta'\mathbf{X}'\mathbf{Y} + \beta'\mathbf{X}'\mathbf{X}\beta \\
  \text{[FOC]}~~~0 & =  - 2\mathbf{X}'\mathbf{Y} + 2\mathbf{X}'\mathbf{X}\hat{\beta}                  \\
  \hat{\beta}      & = (\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\mathbf{Y}                              \\
                   & = (\sum^{n} \mathbf{x}_i \mathbf{x}'_i)^{-1} \sum^{n} \mathbf{x}_i y_i
\end{aligned}
```

$$
\begin{aligned}
  \min Q           & = \min_{\beta} \mathbf{Y}'\mathbf{Y} - 2\beta'\mathbf{X}'\mathbf{Y} +
  \beta'\mathbf{X}'\mathbf{X}\beta \\
                   & = \min_{\beta} - 2\beta'\mathbf{X}'\mathbf{Y} + \beta'\mathbf{X}'\mathbf{X}\beta \\
  \text{[FOC]}~~~0 & =  - 2\mathbf{X}'\mathbf{Y} + 2\mathbf{X}'\mathbf{X}\hat{\beta}                  \\
  \hat{\beta}      & = (\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\mathbf{Y}                              \\
                   & = (\sum^{n} \mathbf{x}_i \mathbf{x}'_i)^{-1} \sum^{n} \mathbf{x}_i y_i
\end{aligned}
$$
